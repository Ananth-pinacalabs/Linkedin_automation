{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as ec\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting selenium\n",
      "  Downloading selenium-4.23.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting urllib3<3,>=1.26 (from urllib3[socks]<3,>=1.26->selenium)\n",
      "  Downloading urllib3-2.2.2-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting trio~=0.17 (from selenium)\n",
      "  Downloading trio-0.26.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting trio-websocket~=0.9 (from selenium)\n",
      "  Downloading trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting certifi>=2021.10.8 (from selenium)\n",
      "  Downloading certifi-2024.7.4-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting typing_extensions~=4.9 (from selenium)\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting websocket-client~=1.8 (from selenium)\n",
      "  Downloading websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting attrs>=23.2.0 (from trio~=0.17->selenium)\n",
      "  Downloading attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting sortedcontainers (from trio~=0.17->selenium)\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting idna (from trio~=0.17->selenium)\n",
      "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting outcome (from trio~=0.17->selenium)\n",
      "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting sniffio>=1.3.0 (from trio~=0.17->selenium)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting cffi>=1.14 (from trio~=0.17->selenium)\n",
      "  Using cached cffi-1.16.0-cp312-cp312-win_amd64.whl.metadata (1.5 kB)\n",
      "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting pysocks!=1.5.7,<2.0,>=1.5.6 (from urllib3[socks]<3,>=1.26->selenium)\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pycparser (from cffi>=1.14->trio~=0.17->selenium)\n",
      "  Downloading pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Collecting h11<1,>=0.9.0 (from wsproto>=0.14->trio-websocket~=0.9->selenium)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Downloading selenium-4.23.1-py3-none-any.whl (9.4 MB)\n",
      "   ---------------------------------------- 0.0/9.4 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.2/9.4 MB 7.6 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.7/9.4 MB 9.3 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 1.1/9.4 MB 9.0 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 1.5/9.4 MB 9.4 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 2.0/9.4 MB 9.0 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 2.5/9.4 MB 10.0 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 3.3/9.4 MB 11.0 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 4.2/9.4 MB 12.6 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 4.4/9.4 MB 11.6 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 5.4/9.4 MB 12.8 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 6.3/9.4 MB 13.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 7.1/9.4 MB 13.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 7.7/9.4 MB 13.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.5/9.4 MB 13.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.4/9.4 MB 14.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.4/9.4 MB 14.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.4/9.4 MB 12.9 MB/s eta 0:00:00\n",
      "Downloading certifi-2024.7.4-py3-none-any.whl (162 kB)\n",
      "   ---------------------------------------- 0.0/163.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 163.0/163.0 kB 9.5 MB/s eta 0:00:00\n",
      "Downloading trio-0.26.0-py3-none-any.whl (475 kB)\n",
      "   ---------------------------------------- 0.0/475.7 kB ? eta -:--:--\n",
      "   --------------------------------------- 475.7/475.7 kB 14.5 MB/s eta 0:00:00\n",
      "Downloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
      "Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading urllib3-2.2.2-py3-none-any.whl (121 kB)\n",
      "   ---------------------------------------- 0.0/121.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 121.4/121.4 kB 7.0 MB/s eta 0:00:00\n",
      "Downloading websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "   ---------------------------------------- 0.0/58.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 58.8/58.8 kB 3.0 MB/s eta 0:00:00\n",
      "Downloading attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "   ---------------------------------------- 0.0/60.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 60.8/60.8 kB 3.4 MB/s eta 0:00:00\n",
      "Using cached cffi-1.16.0-cp312-cp312-win_amd64.whl (181 kB)\n",
      "Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Downloading idna-3.7-py3-none-any.whl (66 kB)\n",
      "   ---------------------------------------- 0.0/66.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 66.8/66.8 kB 3.5 MB/s eta 0:00:00\n",
      "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "   ---------------------------------------- 0.0/58.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 58.3/58.3 kB 3.2 MB/s eta 0:00:00\n",
      "Downloading pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "   ---------------------------------------- 0.0/117.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 117.6/117.6 kB 7.2 MB/s eta 0:00:00\n",
      "Installing collected packages: sortedcontainers, websocket-client, urllib3, typing_extensions, sniffio, pysocks, pycparser, idna, h11, certifi, attrs, wsproto, outcome, cffi, trio, trio-websocket, selenium\n",
      "Successfully installed attrs-23.2.0 certifi-2024.7.4 cffi-1.16.0 h11-0.14.0 idna-3.7 outcome-1.3.0.post0 pycparser-2.22 pysocks-1.7.1 selenium-4.23.1 sniffio-1.3.1 sortedcontainers-2.4.0 trio-0.26.0 trio-websocket-0.11.1 typing_extensions-4.12.2 urllib3-2.2.2 websocket-client-1.8.0 wsproto-1.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting webdriver_manager\n",
      "  Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting requests (from webdriver_manager)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting python-dotenv (from webdriver_manager)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\sudar\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from webdriver_manager) (24.0)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->webdriver_manager)\n",
      "  Downloading charset_normalizer-3.3.2-cp312-cp312-win_amd64.whl.metadata (34 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sudar\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->webdriver_manager) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sudar\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->webdriver_manager) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sudar\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->webdriver_manager) (2024.7.4)\n",
      "Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl (27 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "   ---------------------------------------- 0.0/64.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 64.9/64.9 kB 1.8 MB/s eta 0:00:00\n",
      "Downloading charset_normalizer-3.3.2-cp312-cp312-win_amd64.whl (100 kB)\n",
      "   ---------------------------------------- 0.0/100.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 100.4/100.4 kB 2.9 MB/s eta 0:00:00\n",
      "Installing collected packages: python-dotenv, charset-normalizer, requests, webdriver_manager\n",
      "Successfully installed charset-normalizer-3.3.2 python-dotenv-1.0.1 requests-2.32.3 webdriver_manager-4.0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install webdriver_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#open the webpage\n",
    "driver.get(\"https://www.linkedin.com/login?fromSignIn=true&trk=guest_homepage-basic_nav-header-signin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = []\n",
    "with open(\"links.txt\", \"r\") as links:\n",
    "    links = links.readline().split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.linkedin.com/jobs/search/?currentJobId=3947262572&keywords=machine%20learning&origin=SWITCH_SEARCH_VERTICAL',\n",
       " 'https://www.linkedin.com/jobs/search/?currentJobId=3967471753&geoId=102713980&keywords=deep%20learning&origin=JOB_SEARCH_PAGE_SEARCH_BUTTON&refresh=true',\n",
       " 'https://www.linkedin.com/jobs/search/?currentJobId=3981401852&geoId=102713980&keywords=computer%20vision&origin=JOB_SEARCH_PAGE_SEARCH_BUTTON&refresh=true']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(links[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = WebDriverWait(driver, 50).until(ec.element_to_be_clickable((By.CSS_SELECTOR, \"input[id='username']\")))\n",
    "password = WebDriverWait(driver, 50).until(ec.element_to_be_clickable((By.CSS_SELECTOR, \"input[id='password']\")))\n",
    "username.clear()\n",
    "username.send_keys(\"iamananth123@gmail.com\")\n",
    "password.clear()\n",
    "password.send_keys(\"anantharaman\")\n",
    "\n",
    "\n",
    "submit_button = WebDriverWait(driver, 50).until(ec.element_to_be_clickable((By.CSS_SELECTOR, \"button[type='submit']\")))\n",
    "submit_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(links[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_list = WebDriverWait(driver, 10).until(ec.element_to_be_clickable((By.CSS_SELECTOR, \"ul[class='scaffold-layout__list-container']\")))\n",
    "job_cards = job_list.find_elements(By.XPATH, \".//div[@data-view-name = 'job-card']\")\n",
    "(driver).execute_script(\"arguments[0].scrollTo(0,6000000);\", job_list);\n",
    "\n",
    "#  By.XPATH,\"//div[@class = '_ab8w  _ab94 _ab97 _ab9f _ab9k _ab9p  _ab9- _aba8 _abcm']\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_card = job_cards[2]\n",
    "link = job_card.find_element(By.XPATH, \".//a\")\n",
    "link.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company name:  Samsung Electro-Mechanics\n",
      "job_title:  Image Processing Engineer\n"
     ]
    }
   ],
   "source": [
    "job_desc_panel = WebDriverWait(driver, 10).until(ec.element_to_be_clickable((By.CSS_SELECTOR, \"div[class='jobs-search__job-details--wrapper']\")))\n",
    "\n",
    "\n",
    "(driver).execute_script(\"arguments[0].scrollTo(0,6000000);\", job_desc_panel)\n",
    "\n",
    "\n",
    "\n",
    "company_name =  job_desc_panel.find_element(By.XPATH, \".//div[@class = 'job-details-jobs-unified-top-card__company-name']\").text\n",
    "job_title = job_desc_panel.find_element(By.XPATH,\".//h1[@class = 't-24 t-bold inline']\")\n",
    "\n",
    "print(\"company name: \", company_name)\n",
    "print(\"job_title: \", job_title.text)\n",
    "\n",
    "\n",
    "\n",
    "# job_desc = job_desc_panel.find_element(By.XPATH, \".//div[@class = 'mt4']\")\n",
    "# desciptions = job_desc.find_elements(By.TAG_NAME, \"span\")\n",
    "# text = \"\"\n",
    "# desciptions\n",
    "\n",
    "# text_sections = []\n",
    "\n",
    "# for section in desciptions:\n",
    "#     text_sections.append(section.find_element(By.TAG_NAME, \"p\").text)\n",
    "\n",
    "# text_sections\n",
    "# desciptions[1].find_element(By.TAG_NAME, \"p\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# desciptions.text\n",
    "\n",
    "# comapany_page =  \n",
    "# job_title.text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "On-site\n",
      "Matches your job preferences, workplace type is On-site.\n",
      "Full-time\n",
      "Matches your job preferences, job type is Full-time.\n",
      "Entry level\n",
      "Skills: Python (Programming Language), Credit Risk Modeling Tools, +2 more\n",
      "See how you compare to over 100 other people who clicked Apply. Reactivate Premium\n",
      "\n",
      "Am I a good fit for this job?\n",
      "How can I best position myself for this job?\n",
      "Tell me more about Groww\n",
      "Radical customer centricity\n",
      "Ownership-driven culture\n",
      "Keeping everything simple\n",
      "Long-term thinking\n",
      "Complete transparency\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "job_desc_panel = WebDriverWait(driver, 10).until(ec.element_to_be_clickable((By.CSS_SELECTOR, \"div[class = 'jobs-search__job-details--wrapper']\")))\n",
    "text = job_desc_panel.find_elements(By.TAG_NAME, \"li\")\n",
    "out_text = \"\"\n",
    "for t in text:\n",
    "    out_text = out_text + \"\\n\" + t.text\n",
    "\n",
    "\n",
    "print(out_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"On-site\\nMatches your job preferences, workplace type is On-site.\\nFull-time\\nMatches your job preferences, job type is Full-time.1 school alum works hereSkills: Deep Learning, Machine Learning, +8 moreSee how you compare to over 100 other applicants. Reactivate PremiumAm I a good fit for this job?How can I best position myself for this job?Tell me more about ClutterbotAbout ClutterbotImagine a world where you never have to worry about picking up clutter again! At our robotics startup, we understand the challenges families face trying to balance work and daily responsibilities while keeping their homes tidy. That's why we're developing a cutting-edge household robot that will revolutionize the way you live. This safe and innovative robot will drive around your house, effortlessly picking up toys, clothes, and other items off the floor and organizing them neatly into containers. Say goodbye to clutter and hello to a more efficient andstress-free home life!As part of our close-knit team, you'll have the opportunity to work on cutting-edge technology and be at the forefront of the robotics industry. You'll also have the chance to grow your skills and expertise through collaboration with experienced professionals in the field. Join us in building the future of home automation and experience a fulfilling and rewarding career journey!About The RoleWe seek a motivated ML Engineer to join our team and specialize in core deep learning and computer vision.You will be responsible for developing and fine-tuning deep-learning models that enhance our robot's capabilities. You will play a critical role in ensuring that our ML models are robust, scalable, and efficientResponsibilities● Develop and deploy deep learning models for computer vision tasks such as semantic segmentation, object detection, and image classification.● Fine-tune and optimize deep learning models to improve performance and efficiency.● Work closely with the data science team to identify key metrics and data sources for fine-tuning the deep learning models.● Develop and implement algorithms and models that efficiently learn from new data and adapt to changing environmental conditions.● Develop and implement data processing pipelines to efficiently extract features and label data for ML model training.● Collaborate with cross-functional teams, including software engineers and product managers, to ensure successful delivery of ML models.● Stay up-to-date with the latest developments in deep learning and make recommendations for improvements to ML models and training pipelinesRequirements● Bachelor's or Master's degree in Computer Science, Electrical Engineering, Mathematics, or a related field.● 3+ years of experience in deep learning engineering, focusing on developing and deploying DL models.● Experience training and deploying deep learning computer vision models such as semantic segmentation, object detection, and image classification.● Strong programming skills in Python or similar languages.● Strong experience with popular deep learning frameworks such as TensorFlow or PyTorch.● Strong experience with data processing and feature extraction techniques.● Experience in working on deep learning model training and optimization for edge devices such as Nvidia Jetson.● Familiarity with on-device learning and the challenges associated with it.● Strong problem-solving and analytical skills, with the ability to analyze complex systems and identify areas for improvement.● Excellent communication and collaboration skills, with the ability to work effectively in a team environment.If you are a highly motivated ML Engineer and passionate about developing on-device learning solutions for home robots, we encourage you to apply for this exciting opportunity. You will have the opportunity to work with cutting-edge technologies and collaborate with a talented team of data scientists and software engineers to create innovative solutions for our customersBenefits-Competitive compensation package-Health Insurance-Flexible work culture-Company-Sponsored Devices-Health/Wellness Membership Benefits-Team building activitiesMedical insuranceCommute to this job's locationWorking in an onsite settingGet exclusive access to applicant insights, see jobs where you’d be a top applicant and moreThejus and millions of other members use PremiumCancel anytime, for any reason.At Clutterbot, we're developing a safe household robot for tidying up rooms and organizing things at home. The robot drives around the house, picks toys and clothing off the floor and organizes them into containers.\\n…\\nshow more\""
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_desc_panel = WebDriverWait(driver, 10).until(ec.element_to_be_clickable((By.CSS_SELECTOR, \"div[class = 'jobs-search__job-details--wrapper']\")))\n",
    "child_elements = job_desc_panel.find_elements(By.XPATH, \".//*\")\n",
    "\n",
    "out_text = \"\"\n",
    "for element in child_elements:\n",
    "    if element.tag_name in [\"p\", \"li\"]:\n",
    "        out_text += element.text\n",
    "\n",
    "\n",
    "out_text\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "About Groww\n",
      "We are a passionate group of people focused on making financial services accessible to every Indian through a multi-product platform. Each day, we help millions of customers take charge of their financial journey. Customer obsession is in our DNA. Every product, every design, and every algorithm down to the tiniest detail is executed keeping the customers’ needs and convenience in mind. Our people are our greatest strength. Everyone at Groww is driven by ownership, customer-centricity, integrity, and the passion to constantly challenge the status quo.\n",
      "\n",
      "Are you as passionate about defying conventions and creating something extraordinary as we are? Let’s chat.\n",
      "\n",
      "Our Vision\n",
      "Every individual deserves the knowledge, tools, and confidence to make informed financial decisions. At Groww, we are making sure every Indian feels empowered to do so through a cutting-edge multi-product platform offering a variety of financial services.\n",
      "\n",
      "Our long-term vision is to become the trusted financial partner for millions of Indians.\n",
      "\n",
      "Our Values\n",
      "Our culture enables us to be what we are — India’s fastest-growing financial services company. Everyone at Groww enjoys the autonomy and flexibility to bring their best work to the table, as well as craft a promising career for themselves.\n",
      "\n",
      "The values that form our foundation are:\n",
      "\n",
      "Key Responsibilities:\n",
      "• Responsible for solving business problems using data science in the credit risk domain.\n",
      "• Work closely with the credit risk team to formulate risk policies and build scorecards.\n",
      "• Mentor and guide junior team members in achieving data science outcomes and handling multiple initiatives.\n",
      "• Discuss and work with the credit business and risk leadership team to align and work on key focus areas.\n",
      "• Follow industry best practices, and stay up to date with the latest machine learning techniques for\n",
      "implementation in ongoing projects.\n",
      "• Participate in internal technical councils and represent the organization in forums that involve\n",
      "the community of data scientists across industry and academia.\n",
      "• Promote and support company policies, procedures, mission, values, and standards of ethics and\n",
      "integrity.\n",
      "\n",
      "Skills And Expertise:\n",
      "Experience: 2 to 4 Years\n",
      "• Mandatory experience in model development in credit risk (acquisition, behavior, and collections scorecard) for retail credit products.\n",
      "• Know-how of credit risk management and usage of risk policies.\n",
      "• Knowledge of Bureau data and other alternate data sources, a strong foundation of machine learning and statistics for building credit scorecards.\n",
      "• Strong Python coding skills.\n",
      "• Ability to work in a big data ecosystem - knowledge of SQL/Big query.\n",
      "• Strong ability to understand the business and good stakeholder management capabilities and has mentored data scientists in developing ML solutions.\n",
      "• Experience playing the role of full-stack data scientist and taking solutions to production.\n",
      "• Education/Qualification: Any Graduate/PG.\n",
      "Get exclusive access to applicant insights, see jobs where you’d be a top applicant and more\n",
      "Thejus and millions of other members use Premium\n",
      "Cancel anytime, for any reason.\n",
      "We are a strong and enthusiastic team focused on making financial services accessible to every Indian through a multi-product platform. Each day, we help millions of customers take charge of their financial journey.\n",
      "\n",
      "Customer obsession is in our DNA. Every product, every design, every algorithm down to the tiniest detail is executed keeping the customers’ needs and convenience in mind.\n",
      "\n",
      "Our people are our greatest strength. Everyone at Groww is driven by ownership, customer-centricity, integrity and the passion to constantly challenge the status quo.\n",
      "\n",
      "Are you as passionate about defying conventions and creating something extraordinary as we are? Let’s chat.\n",
      "\n",
      "Our Vision\n",
      "\n",
      "Every individual deserves the knowledge, tools, and confidence to make informed financial decisions. At Groww, we are making sure every Indian feels empowered to do so through a cutting-edge multi-product platform offering a variety of financial services.\n",
      "\n",
      "Our long-term vision is to become the trusted financial partner for millions of Indians.\n",
      "\n",
      "Our Values\n",
      "\n",
      "Our culture enables us to be what we are — India’s fastest-growing financial services company. Everyone at Groww enjoys the autonomy and flexibility to bring their best work to the table, as well as craft a promising career for themselves.\n",
      "\n",
      "The values that form our foundation are:\n",
      "Customer centricity\n",
      "Ownership-driven culture\n",
      "Keeping everything simple\n",
      "Long-term thinking\n",
      "Complete transparency\n",
      "\n",
      "Groww is India’s No.1 Stock Broker based on active clients user data as per NSE as on 30 June 2024, and is the largest distributor of Mutual Funds SIPs.\n",
      "…\n",
      "show more\n",
      "Privately share your profile with our recruiters – you’ll be noted as expressing interest for up to a year. Learn more\n",
      "Learn more about Interested in working for our company\n"
     ]
    }
   ],
   "source": [
    "text = job_desc_panel.find_elements(By.TAG_NAME, \"p\")\n",
    "\n",
    "out_text = \"\"\n",
    "for t in text:\n",
    "    out_text = out_text + \"\\n\" + t.text\n",
    "\n",
    "\n",
    "print(out_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\".//div[@class = 'jobs-search__job-details--wrapper']\"}\n  (Session info: chrome=126.0.6478.127); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n\tGetHandleVerifier [0x00EEC203+27395]\n\t(No symbol) [0x00E83E04]\n\t(No symbol) [0x00D81B7F]\n\t(No symbol) [0x00DC2C65]\n\t(No symbol) [0x00DC2D3B]\n\t(No symbol) [0x00DB8D01]\n\t(No symbol) [0x00DE39E4]\n\t(No symbol) [0x00DB8C15]\n\t(No symbol) [0x00DE3C34]\n\t(No symbol) [0x00DFCB24]\n\t(No symbol) [0x00DE3736]\n\t(No symbol) [0x00DB7541]\n\t(No symbol) [0x00DB80BD]\n\tGetHandleVerifier [0x011A3AB3+2876339]\n\tGetHandleVerifier [0x011F7F7D+3221629]\n\tGetHandleVerifier [0x00F6D674+556916]\n\tGetHandleVerifier [0x00F7478C+585868]\n\t(No symbol) [0x00E8CE44]\n\t(No symbol) [0x00E89858]\n\t(No symbol) [0x00E899F7]\n\t(No symbol) [0x00E7BF4E]\n\tBaseThreadInitThunk [0x76627BA9+25]\n\tRtlInitializeExceptionChain [0x7780BE3B+107]\n\tRtlClearBits [0x7780BDBF+191]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m desciption_div \u001b[38;5;241m=\u001b[39m \u001b[43mjob_desc_panel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXPATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.//div[@class = \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mjobs-search__job-details--wrapper\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m span_elements \u001b[38;5;241m=\u001b[39m desciption_div\u001b[38;5;241m.\u001b[39mfind_elements(By\u001b[38;5;241m.\u001b[39mTAG_NAME, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mp\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m span_elements:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\selenium\\webdriver\\remote\\webelement.py:417\u001b[0m, in \u001b[0;36mWebElement.find_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    414\u001b[0m     by \u001b[38;5;241m=\u001b[39m By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR\n\u001b[0;32m    415\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[name=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 417\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFIND_CHILD_ELEMENT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43musing\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\selenium\\webdriver\\remote\\webelement.py:395\u001b[0m, in \u001b[0;36mWebElement._execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    393\u001b[0m     params \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    394\u001b[0m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id\n\u001b[1;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:354\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    352\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 354\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    355\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\".//div[@class = 'jobs-search__job-details--wrapper']\"}\n  (Session info: chrome=126.0.6478.127); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n\tGetHandleVerifier [0x00EEC203+27395]\n\t(No symbol) [0x00E83E04]\n\t(No symbol) [0x00D81B7F]\n\t(No symbol) [0x00DC2C65]\n\t(No symbol) [0x00DC2D3B]\n\t(No symbol) [0x00DB8D01]\n\t(No symbol) [0x00DE39E4]\n\t(No symbol) [0x00DB8C15]\n\t(No symbol) [0x00DE3C34]\n\t(No symbol) [0x00DFCB24]\n\t(No symbol) [0x00DE3736]\n\t(No symbol) [0x00DB7541]\n\t(No symbol) [0x00DB80BD]\n\tGetHandleVerifier [0x011A3AB3+2876339]\n\tGetHandleVerifier [0x011F7F7D+3221629]\n\tGetHandleVerifier [0x00F6D674+556916]\n\tGetHandleVerifier [0x00F7478C+585868]\n\t(No symbol) [0x00E8CE44]\n\t(No symbol) [0x00E89858]\n\t(No symbol) [0x00E899F7]\n\t(No symbol) [0x00E7BF4E]\n\tBaseThreadInitThunk [0x76627BA9+25]\n\tRtlInitializeExceptionChain [0x7780BE3B+107]\n\tRtlClearBits [0x7780BDBF+191]\n"
     ]
    }
   ],
   "source": [
    "desciption_div = job_desc_panel.find_element(By.XPATH, \".//div[@class = 'jobs-search__job-details--wrapper']\")\n",
    "\n",
    "text = desciption_div.find_elements(By.TAG_NAME, \"\")\n",
    "\n",
    "for i in span_elements:\n",
    "    print(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"skills.txt\",\"r\") as skills:\n",
    "    skills_list  = skills.readline()\n",
    "\n",
    "\n",
    "\n",
    "skill_keywords  =  [i.strip() for i in skills_list.split(\",\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JavaScript\n",
      "Hive\n",
      "Pig\n",
      "MapReduce\n",
      "HBase\n",
      "Cassandra\n",
      "Data Mining\n",
      "Machine Learning\n",
      "Deep Learning\n",
      "Neural Networks\n",
      "Natural Language Processing\n",
      "Computer Vision\n",
      "CV\n",
      "Data Visualization\n",
      "Big Data\n",
      "Statistics\n",
      "Mathematics\n",
      "Linear Algebra\n",
      "Calculus\n",
      "Probability\n",
      "Data Analysis\n",
      "Data Wrangling\n",
      "Feature Engineering\n",
      "Data Cleaning\n",
      "Business Intelligence\n",
      "BI\n",
      "Data Ware\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "with open(\"skills2.txt\",\"r\") as skills:\n",
    "    skills_list  = skills.readline()\n",
    "\n",
    "\n",
    "\n",
    "skill_keywords2  =  [i.strip() for i in skills_list.split(\",\")]\n",
    "\n",
    "\n",
    "i = 0\n",
    "for word in skill_keywords2:\n",
    "    if word not in skill_keywords:\n",
    "        print(word)\n",
    "        i+=1\n",
    "\n",
    "print(i)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python, R, SQL, Java, C++, Scala, JavaScript, TensorFlow, Keras, PyTorch, scikit-learn, NumPy, Pandas, Matplotlib, Seaborn, Hadoop, Spark, Hive, Pig, MapReduce, HBase, Cassandra, Data Mining, Machine Learning, Deep Learning, Neural Networks, Natural Language Processing, NLP, Computer Vision, CV, Data Visualization, Big Data, Statistics, Mathematics, Linear Algebra, Calculus, Probability, Data Analysis, Data Wrangling, Feature Engineering, Data Cleaning, ETL, Business Intelligence, BI, Tableau, Power BI, Excel, Data Ware\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(skills_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_keyword_list = list(set(skill_keywords2) | set(skill_keywords))\n",
    "len(final_keyword_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"keywords_skills.txt\", mode='w') as file:\n",
    "    file.write(','.join(final_keyword_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the keywords from the file\n",
    "with open(\"Skills_Keywords.txt\", \"r\") as file:\n",
    "    skill_keywords = file.read().strip().split(',')\n",
    "\n",
    "\n",
    "\n",
    "# Normalize the keywords to lowercase\n",
    "skill_keywords = [keyword.strip().lower() for keyword in skill_keywords]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_skills(job_description, skill_keywords):\n",
    "    # Normalize the job description\n",
    "    job_description = job_description.lower()\n",
    "\n",
    "    # Extract the skills found in the job description\n",
    "    found_skills = set()\n",
    "    for skill in skill_keywords:\n",
    "        # Use regular expressions to account for whole words and avoid partial matches\n",
    "        if re.search(r'\\b' + re.escape(skill) + r'\\b', job_description):\n",
    "            found_skills.add(skill)\n",
    "    \n",
    "    return list(found_skills)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 Skills found in the job description: ['machine learning', 'programming', 'optimization', 'tensorflow', 'pytorch', 'deep learning', 'classification', 'collaboration', 'object detection', 'computer vision', 'problem-solving', 'python', 'mathematics']\n"
     ]
    }
   ],
   "source": [
    "found_skills = extract_skills(out_text, skill_keywords)\n",
    "print(len(found_skills),  \"Skills found in the job description:\", found_skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nOn-site\\nMatches your job preferences, workplace type is On-site.\\nFull-time\\nMatches your job preferences, job type is Full-time.\\nEntry level\\nSkills: Python (Programming Language), Credit Risk Modeling Tools, +2 more\\nSee how you compare to over 100 other people who clicked Apply. Reactivate Premium\\n\\nAm I a good fit for this job?\\nHow can I best position myself for this job?\\nTell me more about Groww\\nRadical customer centricity\\nOwnership-driven culture\\nKeeping everything simple\\nLong-term thinking\\nComplete transparency\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
